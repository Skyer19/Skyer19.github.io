<!DOCTYPE HTML>

<html>
  <head>
    <title>Linux Operation</title>

  <style>
      .highlight {
          background-color: yellow;
      }
  </style>
  </head>
  <body>

    <H2>Code</h2>

    <b class="highlight">测试网络参数是否正确</b>
    <pre>
      class Generator(nn.Module):
      def __init__(self):
          super(Generator, self).__init__()
          
          self.generator = nn.Sequential(
  
              nn.ConvTranspose2d(in_channels=latent_vector_size, out_channels=1024, kernel_size=4, stride=1, padding=0, bias=False),
              nn.BatchNorm2d(1024),
              nn.ReLU(),
              
              nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),
              nn.BatchNorm2d(512),
              nn.ReLU(),
              
              nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),
              nn.BatchNorm2d(256),
              nn.ReLU(),
              
              nn.ConvTranspose2d(in_channels=256, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False),
              # nn.BatchNorm2d(128),
              # nn.ReLU(),
  
              # nn.ConvTranspose2d(in_channels=128, out_channels=3, kernel_size=4, stride=2, padding=1),
              nn.Tanh()
          )
          
      def forward(self, z):
          out = self.generator(z)
  
          return out
    </pre>
    
    <pre>
      input_tensor = torch.randn((128, 100, 1, 1))

      model = Generator()

      # 使用hook打印每个层的输出尺寸
      def print_size(module, input, output):
          print(output.size())

      # 注册hook
      for layer in model.generator:
          if isinstance(layer, nn.ConvTranspose2d):
              layer.register_forward_hook(print_size)

      # 前向传播以打印尺寸
      with torch.no_grad():
          model(input_tensor)
    </pre>





  </body>




</html>
