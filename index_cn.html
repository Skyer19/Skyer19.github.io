<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>林洛君 (Luojun Lin)</title>
<style>
	table{
		border: none;
	}
	table td{
		border: none;
	}
</style>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>林洛君 (Luojun Lin)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://RojunLin.github.io//"><img src="picture/luojun.jpg" alt="alt text" width="150px" /></a>&nbsp;</td>
<td align="left"><p>讲师，校聘副教授<br />
<a href="https://csip.fzu.edu.cn/">认知系统与信息处理实验室</a>, <br />
<a href="https://ccds.fzu.edu.cn/">计算机与大数据学院</a>,  <br />
<a href="https://www.fzu.edu.cn/">福州大学</a>, <br />
福建省福州市福州大学城乌龙江北大道2号<br />
邮编：350108 <br />
邮箱: <a href= "mailto:ljlin@fzu.edu.cn">ljlin@fzu.edu.cn</a>  <br />
<br />
<a href="https://scholar.google.com/citations?user=b5jpNUEAAAAJ&hl=zh-CN&oi=ao">[Google Scholar]</a> 
  <a href="https://github.com/RojunLin">[GitHub]</a><a href="index.html">[English Page]</a></p>
</td></tr></table>
<h2>关于我</h2>
<p>我目前是福州大学计算机与大数据学院讲师，校聘副教授。
本人于2015年从云南大学获得学士学位，于2020年从<a href="http://www.scut.edu.cn/">华南理工大学</a>获得博士（师从<a href="https://scholar.google.com/citations?user=WMUStEUAAAAJ&hl=zh-CN&oi=ao">金连文教授</a>）学位。
2020年加入福州大学计算机与大数据学院认知系统与信息处理实验室。目前已在CCF A/B/C类会议/期刊上发表多篇论文，担任CVPR、ECCV、IEEE TCYB/TAFFC/TMM、Neurocomputing等多个国际知名会议与期刊的审稿人。 </p>
<p>我的研究兴趣主要包括：深度学习，计算机视觉，迁移学习、自主学习等。</p>

	<a name="publication"><h3>预印本</h3></a>
	<hr />
	<!-- paper 1-->
	<table><tbody><tr >
	<td valign="top" align="center" width="220" id="FINN"><img src="picture/paper/ssdg.png" width="200" height="104" >
	</td>
	<td>
		<div align="left">
			<i>Semi-Supervised Domain Generalization in Real World: New Benchmark and Strong Baseline</i>
			<br>
				<b>Luojun Lin</b>, Han Xie, Zhifeng Yang, Zhishu Sun, Wenxi Liu, Yuanlong Yu, Weijie Chen, Shicai Yang, Di Xie<br>
		  Arxiv. 2022
			<br>
		  <a href="https://arxiv.org/pdf/2111.10221v2.pdf" style="color:#000000;">Paper</a> | 
		  &nbsp;<a href="https://github.com/MetaVisionLab/SSDG" style="color:#000000;">Code</a> | 
		</div>
	</td>
	</tr></tbody></table> 
<br>


	<!--<hr />-->

	<a name="publication"><h3>已发表</h3></a>
	<!--<a name="publication"><h4>Technical Reports</h4></a>-->
	<hr />


	<!-- paper 2 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="PQ-NET"><img src="picture/paper/ddg.png" width="200" height="144" border="0">
	</td>
	<td>
		<div align="left">
			<i>Dynamic Domain Generalization</i>
			<br>
			Zhishu Sun, Zhifeng Shen, <b>Luojun Lin*</b>, Yuanlong Yu, Zhifeng Yang, Shicai Yang, Weijie Chen<br>
		   International Joint Conference on Artificial Intelligence (IJCAI), 2022
	   
		   <br>
		   <a href="https://arxiv.org/pdf/2205.13913.pdf" style="color:#000000;">Paper</a>  | 
		   &nbsp;<a href="https://github.com/MetaVisionLab/DDG" style="color:#000000;">Code</a> | 
		</div>
	</td>
	</tr></tbody></table> 
<br>



	<!-- paper 3 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="PQ-NET"><img src="picture/paper/ssnll.png" width="200" height="144" border="0">
	</td>
	<td>
		<div align="left">
			<i>Self-Supervised Noisy Label Learning for Source-Free Unsupervised Domain Adaptation</i>
			<br>
			Weijie Chen+, <b>Luojun Lin+</b>, Shicai Yang, Di Xie, Shiliang Pu, Yueting Zhuang (+ co-first authors)<br>
		   IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022
	   
		   <br>
		   <a href="https://arxiv.org/pdf/2102.11614.pdf" style="color:#000000;">Paper</a>  | 
		   &nbsp;<a href="https://github.com/MetaVisionLab" style="color:#000000;">Code</a> | 
		</div>
	</td>
	</tr></tbody></table> 
<br>



	<!-- paper 4 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="PQ-NET"><img src="picture/paper/slimda.png" width="200" height="105" border="0">
	</td>
	<td>
		<div align="left">
			<i>Slimmable Domain Adaptation</i>
			<br>
				Rang Meng, Weijie Chen, Shicai Yang, Jie Song, <b>Luojun Lin</b>, Di Xie, Shiliang Pu, Xinchao Wang, Mingli Song, Yueting Zhuang<br>
		 Computer Vision and Pattern Recognition (CVPR), 2022
	 
		 <br>
		 <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_Slimmable_Domain_Adaptation_CVPR_2022_paper.pdf" style="color:#000000;">Paper</a>  | 
		 &nbsp;<a href="https://github.com/HIK-LAB/SlimDA" style="color:#000000;">Code</a> | 
		 &nbsp;<a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Meng_Slimmable_Domain_Adaptation_CVPR_2022_supplemental.pdf" style="color:#000000;">Supplementary</a> | 	 
		</div>
	</td>
	</tr></tbody></table> 
<br>


	<!-- paper 5 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="PQ-NET"><img src="picture/paper/synsig2vec-v2.png" width="200" height="117" border="0">
	</td>
	<td>
		<div align="left">
			<i>SynSig2Vec: Forgery-Free Learning of Dynamic Signature Representations by Sigma Lognormal-Based Synthesis and 1D CNN</i>
			<br>
				Songxuan Lai , Lianwen Jin , Yecheng Zhu, Zhe Li, and <b>Luojun Lin</b><br>
		  IEEE Transactions on Pattern Analysis and Machine Learning (TPAMI), 2021
	  
		  <br>
		  <a href="https://ieeexplore.ieee.org/abstract/document/9448392" style="color:#000000;">Paper</a> | 
		  &nbsp;<a href="https://github.com/LaiSongxuan/SynSig2Vec" style="color:#000000;">Code</a> | 
		</div>
	</td>
	</tr></tbody></table> 
<br>


	<!-- paper 6 -->
	<table><tbody><tr>
	<td valign="center" align="center" width="220" id="surfaceRemesh"><img src="picture/paper/synsig2vec-v1.png" width="200" height="49" border="0">
	</td>
	<td>
		<div align="left">
			<i>SynSig2Vec: Learning Representations from Synthetic Dynamic Signatures for Real-World Verification</i>
			<br>
				Songxuan Lai, Lianwen Jin, <b>Luojun Lin</b>, Yecheng Zhu, Huiyun Mao</b><br>
	  
		  Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2020
			<br>
		  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5416" style="color:#000000;">Paper</a> | 
		</div>
	</td>
	</tr></tbody></table> 
<br>



	<!-- paper 7 -->
	<table><tbody><tr>
	<td valign="center" align="center" width="220" id="surfaceRemesh"><img src="picture/paper/uic.png" width="200" height="49" border="0">
	</td>
	<td>
		<div align="left">
			<i>Unsupervised Image Classification for Deep Representation Learning</i>
			<br>
				Weijie Chen, Shiliang Pu, Di Xie, Shicai Yang, Yilu Guo, <b>Luojun Lin</b><br>
	  
		  European Conference on Computer Vision (ECCV), 2020
			<br>
		  <a href="https://link.springer.com/chapter/10.1007/978-3-030-66096-3_30" style="color:#000000;">Paper</a> | 
			  &nbsp;<a href="https://github.com/HIK-LAB/Unsupervised-Image-Classification" style="color:#000000;">Code</a> | 
		</div>
	</td>
	</tr></tbody></table> 
<br>

	<!-- paper 8 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="FeatureSeg"><img src="picture/paper/aaconv.png" width="150" height="117" border="0">
	</td>
	<td>
		<div align="left">
			<i>Attribute-Aware Convolutional Neural Networks for Facial Beauty Prediction.</i>
			<br>
				<b>Luojun Lin</b>, Lingyu Liang, Lianwen Jin, Weijie Chen<br>
	  
		  International Joint Conference on Artificial Intelligence (IJCAI), 2019
			<br>
		  <a href="https://www.ijcai.org/Proceedings/2019/0119.pdf" style="color:#000000;">Paper</a> | 
		  &nbsp;<a href="https://github.com/RojunLin/DynamicConvolution_FBP" style="color:#000000;">Code</a> | 
		</div>
	</td>
	</tr></tbody></table> 
<br>

	<!-- paper 9 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="GeoTopo"><img src="picture/paper/r3cnn.png" width="180" height="117" border="0">
	</td>
	<td>
		<div align="left">
			<i>Regression Guided by Relative Ranking Using Convolutional Neural Network (R3CNN) for Facial Beauty Prediction</i>
			<br>
				<b>Luojun Lin</b>, Lingyu Liang, Lianwen Jin<br>
	  
		  IEEE Transactions on Affective Computing (TAFFC), 2019
			<br>
		  <a href="https://ieeexplore.ieee.org/abstract/document/8789541" style="color:#000000;">Paper</a> | 
		  &nbsp;<a href="https://github.com/RojunLin/R-3CNN" style="color:#000000;">Code</a> | 
		</div>
	</td>
	</tr></tbody></table> 
<br>

 	<!-- paper 10 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="3DLiveWire"><img src="picture/paper/r2resnext.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>R2-ResNeXt: A ResNeXt-Based Regression Model with Relative Ranking for Facial Beauty Prediction</i>
			<br>
				<b>Luojun Lin</b>, Lingyu Liang, Lianwen Jin<br>
	  
		  International Conference on Pattern Recognition (ICPR), 2018
			<br>
		  <a href="https://ieeexplore.ieee.org/abstract/document/8545164" style="color:#000000;">Paper</a> | 
			  &nbsp;<a href="https://github.com/RojunLin/R-3CNN" style="color:#000000;">Code</a> | 
		</div>
	</td>
	</tr></tbody></table> 
 <br>              
 
 	<!-- paper 11 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="3DLiveWire"><img src="picture/paper/scut-fbp5500.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>SCUT-FBP5500: A Diverse Benchmark Dataset for Multi-Paradigm Facial Beauty Prediction</i>
			<br>
				Lingyu Liang; <b>Luojun Lin</b>; Lianwen Jin; Duorui Xie; Mengru Li<br>
	  
		  International Conference on Pattern Recognition (ICPR), 2018
			<br>
		  <a href="https://ieeexplore.ieee.org/abstract/document/8546038/" style="color:#000000;">Paper</a> | 
		  &nbsp;<a href="https://github.com/HCIILAB/SCUT-FBP5500-Database-Release" style="color:#000000;">Dataset</a> | 
		</div>
	</td>
	</tr></tbody></table> 
 <br>    

<br><br>                                                                                                
	<a name="publication"><h3> </h3></a>
	<hr />

</div>

<div id="footer">
<div id="footer-text">
<br>Last updated：2022/11/20, by <a href= "mailto:ljlin@fzu.edu.com">Luojun Lin</a>.
</div>
</div>

</body>
</html>
